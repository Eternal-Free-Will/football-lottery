import os
import re
import time
import pandas as pd
import requests
from bs4 import BeautifulSoup
from openpyxl import load_workbook
from openpyxl.styles import Alignment, Font
from selenium import webdriver
from selenium.webdriver.chrome.service import Service
from selenium.webdriver.chrome.options import Options
from selenium.webdriver.common.by import By
from selenium.webdriver.support.ui import WebDriverWait
from selenium.webdriver.support import expected_conditions as EC
from webdriver_manager.chrome import ChromeDriverManager

from è¯»å–é…ç½®æ–‡ä»¶æ¨¡å— import load_config

# ğŸ¯ ç›®æ ‡å…¬å¸åˆ—è¡¨
TARGET_COMPANIES = ["36", "Bet365", "Crown", "æ¾³é—¨", "æ¾³å½©"]

# âœ… ä»åˆç›˜é¡µé¢æŠ“å–åˆç›˜èµ”ç‡ & å‡¯åˆ©å€¼
def get_initial_1x2_from_history(url):
    try:
        response = requests.get(url, timeout=10)
        response.encoding = "utf-8"
        soup = BeautifulSoup(response.text, "html.parser")
        rows = soup.select("table tr")

        for row in reversed(rows):
            if "(åˆç›˜)" in row.get_text():
                cols = row.find_all("td")
                if len(cols) >= 11:
                    return {
                        "åˆç›˜ä¸»èƒœèµ”ç‡": cols[0].get_text(strip=True),
                        "åˆç›˜å¹³å±€èµ”ç‡": cols[1].get_text(strip=True),
                        "åˆç›˜å®¢èƒœèµ”ç‡": cols[2].get_text(strip=True),
                        "åˆç›˜ä¸»å‡¯åˆ©": cols[7].get_text(strip=True),
                        "åˆç›˜å¹³å‡¯åˆ©": cols[8].get_text(strip=True),
                        "åˆç›˜å®¢å‡¯åˆ©": cols[9].get_text(strip=True)
                    }
        return None
    except Exception as e:
        print("âŒ è¯·æ±‚åˆç›˜é¡µé¢å¤±è´¥ï¼š", str(e))
        return None

def get_driver():
    options = Options()
    options.add_argument('--headless=new')
    options.add_argument('--no-sandbox')
    options.add_argument('--disable-gpu')
    options.add_argument('--window-size=1920,1080')
    return webdriver.Chrome(service=Service(ChromeDriverManager().install()), options=options)

def parse_1x2_html(html):
    soup = BeautifulSoup(html, "html.parser")
    table = soup.find("table", id="oddsList_tab")
    if not table:
        print("âŒ æ²¡æ‰¾åˆ° oddsList_tab è¡¨æ ¼")
        return None

    rows = table.find_all("tr")

    for row_html in rows:
        cols = row_html.find_all("td")
        if len(cols) < 12:
            continue

        company_text = cols[1].get_text(strip=True)
        if any(key in company_text for key in TARGET_COMPANIES):
            # éå†è¯¥è¡Œæ‰€æœ‰ tdï¼Œå¯»æ‰¾ onclick å±æ€§
            onclick_attr = ""
            for td in row_html.find_all("td"):
                onclick_raw = td.get("onclick", "")
                if "OddsHistory" in onclick_raw:
                    onclick_attr = onclick_raw
                    break

            # ç„¶åä» onclick ä¸­æå– id/sid/cid
            match = re.search(r"OddsHistory\('/OddsHistory\.aspx\?id=(\d+)&sid=(\d+)&cid=(\d+)", onclick_attr)
            if match:
                oid, sid, cid = match.groups()
                history_url = f"https://1x2.titan007.com/OddsHistory.aspx?id={oid}&sid={sid}&cid={cid}&l=0"
                print(f"   ğŸ¯ å…¬å¸ï¼š{company_text} â†’ æŠ“å–åˆç›˜ï¼š{history_url}")
                result = get_initial_1x2_from_history(history_url)

                if result:
                    print("   âœ… è·å–æˆåŠŸï¼š", result)
                    return result
                else:
                    print("   âŒ é¡µé¢æ— åˆç›˜æ•°æ®")
    return None

def fill_initial_1x2_odds(issue="25048"):
    parent_path = os.path.abspath(os.path.join(os.getcwd(), os.pardir))
    excel_path = os.path.join(parent_path, "è¶³å½©åˆ†æ", issue, f"ä¼ ç»Ÿè¶³å½©{issue}æœŸç›˜å£æ•°æ®è¡¥å…….xlsx")

    df = pd.read_excel(excel_path, dtype=str)

    # âœ… è¡¥å­—æ®µåˆ—ï¼ˆå¦‚æœæ²¡æœ‰ï¼‰
    needed_fields = [
        "åˆç›˜ä¸»èƒœèµ”ç‡", "åˆç›˜å¹³å±€èµ”ç‡", "åˆç›˜å®¢èƒœèµ”ç‡",
        "åˆç›˜ä¸»å‡¯åˆ©", "åˆç›˜å¹³å‡¯åˆ©", "åˆç›˜å®¢å‡¯åˆ©"
    ]
    for field in needed_fields:
        if field not in df.columns:
            df[field] = "-"

    # âœ… è¶…é“¾æ¥æå–ï¼ˆå…ˆåŠ è½½ä¸€æ¬¡åŸå§‹å·¥ä½œç°¿ï¼‰
    wb_orig = load_workbook(excel_path)
    ws_orig = wb_orig.active
    link_col_index = df.columns.get_loc("æ¯”èµ›ID") + 1

    hyperlink_map = {}
    for i in range(len(df)):
        cell = ws_orig.cell(row=i + 2, column=link_col_index)
        if cell.hyperlink:
            hyperlink_map[i] = cell.hyperlink.target

    # âœ… æŠ“å–æ•°æ®
    for i, row in df.iterrows():
        link = hyperlink_map.get(i)
        if not link or not link.startswith("http"):
            print(f"â­ï¸ è·³è¿‡ç¬¬ {i+1} è¡Œï¼šæ— æœ‰æ•ˆé“¾æ¥")
            continue

        match = re.search(r"id=(\d+)", link)
        if not match:
            print(f"â­ï¸ è·³è¿‡ç¬¬ {i+1} è¡Œï¼šé“¾æ¥æ ¼å¼å¼‚å¸¸")
            continue

        match_id = match.group(1)
        url = f"https://1x2.titan007.com/oddslist/{match_id}.htm"
        print(f"\nâ¡ï¸ æŠ“å– ç¬¬{i+1}è¡Œ æ¯”èµ›IDï¼š{match_id}")

        try:
            driver = get_driver()
            driver.set_page_load_timeout(20)
            driver.get(url)

            WebDriverWait(driver, 20).until(
                lambda d: d.execute_script("return document.readyState") == "complete"
            )
            driver.execute_script("window.scrollTo(0, document.body.scrollHeight);")
            WebDriverWait(driver, 20).until(
                lambda d: len(d.find_elements(By.XPATH, '//table[@id="oddsList_tab"]/tbody/tr')) >= 5
            )

            html = driver.page_source
            result = parse_1x2_html(html)
            driver.quit()

            if result and isinstance(result, dict):
                for key, val in result.items():
                    df.at[i, key] = val
                print("âœ… å†™å…¥æˆåŠŸï¼š", result)
            else:
                print("âŒ é¡µé¢ç»“æ„å¼‚å¸¸æˆ–æ— ç›®æ ‡å…¬å¸")
                for field in needed_fields:
                    df.at[i, field] = "-"

        except Exception as e:
            print(f"âŒ æŠ¥é”™ æ¯”èµ›ID {match_id}ï¼š{str(e)}")
            for field in needed_fields:
                df.at[i, field] = "-"
            try:
                driver.quit()
            except:
                pass

    # âœ… å†™å…¥ Excel æ–‡ä»¶
    df.to_excel(excel_path, index=False)

    # âœ… åŠ è½½å†™å…¥åçš„æ–‡ä»¶
    wb = load_workbook(excel_path)
    ws = wb.active

    # âœ… è®¾ç½®åˆ—å®½ï¼ˆå¯è‡ªå®šä¹‰ï¼‰
    for col in ws.columns:
        max_len = max(len(str(cell.value)) if cell.value else 0 for cell in col)
        adjusted_width = min(max_len + 12, 30)
        ws.column_dimensions[col[0].column_letter].width = adjusted_width

    # âœ… è®¾ç½®è¡¨å¤´æ ·å¼ï¼ˆåŠ ç²— + å±…ä¸­ï¼‰
    header_font = Font(bold=True)
    center_align = Alignment(horizontal="center", vertical="center")

    for cell in ws[1]:
        cell.font = header_font
        cell.alignment = center_align

    # âœ… æ¢å¤è¶…é“¾æ¥
    for i, url in hyperlink_map.items():
        cell = ws.cell(row=i + 2, column=link_col_index)
        cell.value = "æŸ¥çœ‹ç›˜å£"
        cell.hyperlink = url
        cell.style = "Hyperlink"

    # âœ… ä¿å­˜
    wb.save(excel_path)
    print(f"\nâœ… è¡¨æ ¼å·²ç¾åŒ–å¹¶ä¿å­˜ï¼š{excel_path}")

    print(f"\nâœ… å…¨éƒ¨æ•°æ®å¤„ç†å®Œæˆï¼Œå·²ä¿å­˜ï¼š{excel_path}")

# è¿è¡Œå…¥å£
if __name__ == "__main__":
    issue, date_str = load_config()
    print("å½“å‰æœŸå·:", issue)
    fill_initial_1x2_odds(issue)
